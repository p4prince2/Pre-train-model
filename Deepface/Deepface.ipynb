{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad9c73-c382-4b64-9acc-c7dce516b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "deepface.py\n",
    "\n",
    "A demonstration of DeepFace functionalities for face verification, facial analysis,\n",
    "face recognition, and model export using DeepFace's pre-trained models.\n",
    "\n",
    "Dependencies:\n",
    "    - deepface\n",
    "\n",
    "Author: [Your Name or Team]\n",
    "\"\"\"\n",
    "\n",
    "# Install the DeepFace library (only needed in Colab or first-time use)\n",
    "!pip install deepface\n",
    "\n",
    "from deepface import DeepFace\n",
    "import pprint\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Face Verification\n",
    "# ---------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Verifies whether two given images belong to the same person.\n",
    "\n",
    "Inputs:\n",
    "    img1.jpg: Path to the first image.\n",
    "    img2.jpg: Path to the second image.\n",
    "\n",
    "Output:\n",
    "    Dictionary containing 'verified' status, distance metric, model details, etc.\n",
    "\"\"\"\n",
    "result = DeepFace.verify(\"img1.jpg\", \"img2.jpg\")\n",
    "print(result)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Facial Attribute Analysis\n",
    "# ---------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Analyzes facial attributes from a given image.\n",
    "\n",
    "Inputs:\n",
    "    img_path: Path to the image file.\n",
    "    actions : List of facial attributes to analyze, e.g., ['age', 'gender', 'emotion', 'race'].\n",
    "\n",
    "Output:\n",
    "    List of dictionaries (one per detected face) with predicted attributes and confidence scores.\n",
    "\"\"\"\n",
    "result = DeepFace.analyze(img_path=\"img1.jpg\", actions=['age', 'gender', 'emotion', 'race'])\n",
    "data = result[0]  # Access analysis of the first detected face\n",
    "\n",
    "# Display summary of facial analysis\n",
    "print(\"\\n Facial Analysis Summary\")\n",
    "print(\"----------------------------\")\n",
    "print(f\"Estimated Age       : {data['age']}\")\n",
    "print(f\"Face Confidence     : {round(data['face_confidence'] * 100, 2)}%\")\n",
    "print(f\"Dominant Gender     : {data['dominant_gender'].capitalize()} ({round(data['gender'][data['dominant_gender']], 2)}%)\")\n",
    "print(f\"Dominant Emotion    : {data['dominant_emotion'].capitalize()} ({round(data['emotion'][data['dominant_emotion']], 2)}%)\")\n",
    "print(f\"Dominant Race       : {data['dominant_race'].capitalize()} ({round(data['race'][data['dominant_race']], 2)}%)\")\n",
    "\n",
    "# Display facial region details\n",
    "print(\"\\n Facial Region\")\n",
    "print(\"----------------------------\")\n",
    "region = data['region']\n",
    "print(f\"Bounding Box        : x={region['x']}, y={region['y']}, w={region['w']}, h={region['h']}\")\n",
    "print(f\"Left Eye            : {region['left_eye']}\")\n",
    "print(f\"Right Eye           : {region['right_eye']}\")\n",
    "\n",
    "# Display detailed prediction probabilities\n",
    "print(\"\\n Detailed Prediction Probabilities\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"\\nGender:\")\n",
    "for gender, prob in data['gender'].items():\n",
    "    print(f\"  {gender.capitalize():<10}: {round(prob, 2)}%\")\n",
    "\n",
    "print(\"\\nEmotion:\")\n",
    "for emotion, prob in data['emotion'].items():\n",
    "    print(f\"  {emotion.capitalize():<10}: {round(prob, 2)}%\")\n",
    "\n",
    "print(\"\\nRace:\")\n",
    "for race, prob in data['race'].items():\n",
    "    print(f\"  {race.capitalize():<18}: {round(prob, 2)}%\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Face Recognition\n",
    "# ---------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Performs facial recognition by comparing an unknown image to a database of known faces.\n",
    "\n",
    "Inputs:\n",
    "    img_path: Path to the unknown image (e.g., \"khan.png\").\n",
    "    db_path : Path to the image database directory.\n",
    "\n",
    "Output:\n",
    "    Prints the identity if a match is found.\n",
    "\"\"\"\n",
    "img_path = \"khan.png\"\n",
    "results = DeepFace.find(img_path=img_path, db_path=\"/content/sample_data/image\")\n",
    "\n",
    "if len(results[0]) > 0:\n",
    "    print(\"Match Found!\")\n",
    "    identity = results[0].iloc[0]['identity']\n",
    "    name = identity.split(\"/\")[-1].split(\".\")[0]\n",
    "    print(f\"Person identified: {name}\")\n",
    "else:\n",
    "    print(\"No match found.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Model Export (.h5 format)\n",
    "# ---------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Builds a DeepFace model (VGG-Face) and saves it to a .h5 file for further use.\n",
    "\n",
    "Output:\n",
    "    'vgg_face_model.h5' file containing the serialized Keras model.\n",
    "\"\"\"\n",
    "client = DeepFace.build_model(\"VGG-Face\")\n",
    "keras_model = client.model\n",
    "keras_model.save(\"vgg_face_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
